# Redis作为消息队列升级为KafKa记录
项目当中运营人员发送指定匹配用户(最高用户量几十万的级别)特定的消息,所以这块是确确实实需要使用专业级别的消息队列中间件的,但是可能由于当时开发的各种历史原因导致使用了Redis的队列结构来作为消息队里`lpush,blpop`等命令,项目开发进展到现在,用户量不断增大,包括不同的消息继承进来,包括举报反馈,小纸条(用户间消息发送),活动奖励通知,等等一些不同的消息进来以后,Redis可能会变得不那么可靠.

### Redis作为消息队列
Redis的`pub-sub`模式非常像西式快餐一样,快产快消,全都是因为Redis是使用内存来做存取,所有你生产的消息立马会被消费者一次性全部处理掉,并且没有留下任何痕迹, 同时因为内存总是宝贵的,所以内存上会有限制,当生产者以及消费者上来的时候也会对redis的效率,还有Redis在处理发布和消费big size(10K+的文件)的数据的时候会表现出无法忍受的缓慢

如果有以下场景可以考虑使用Redis作为消息队列

1. 如果你的需求是快产快消的即时消费场景,并且生产的消息立即被消费者消费掉
2. 如果速度是你十分看重的,比如慢了一秒好几千万这种
3. 如果允许出现消息丢失的场景
4. 如果你不需要系统保存你发送过的消息,做到来无影去无踪
5. 需要处理的数据量并不是那么巨大


### KafKa作为消息队列
KafKa的设计精妙,支持分布式,高可用的部署,并且对一个大的队列采用分成多个`Partition`(分区),来提高消息入队的吞吐量,分而治之的思想. 并且消费的时候支持`group`的概念,能够支持多个客户端消费同个队列,并且一个`group`中可以增加consumer的数量来扩展消费的处理量.

KafKa不熟生产者数量的影响,因为吞吐量足够支撑,即使在廉价的单机服务器上也可以有**10万每秒**的消息传输量,并且消费者是想什么时候消费都可以,消息它就在那里,十分灵活,不用担心来无影去无踪的恐慌.能把消息持久化,并以一定的策略(例如一定时间内删除,或者到达多大容量的时候清空)

当有一下场景的时候你可以考虑使用KafKa作为消息队列

1. 如果你想要稳定的消息队列
2. 如果你想要你发送过的消息可以保留一定的时间,并不是无迹可寻的时候
3. 如果你无法忍受数据的丢失
4. 如果速度不需要那么的快
5. 如果需要处理数据量巨大的时候


---

### KafKa的术语解释
上边介绍了`Redis`作为消息队列和`KafKa`的比较,令人震惊的就是KafKa的巨大吞吐量,它的具体设计思想和设计方式是什么样的呢? 究竟是什么导致它可以那么的凶如猛兽?

--代办


### 常见的消息队列如何保证消息的可靠性

MQ作为消息队列提供了解耦,提高数据消费和生产的性能,但是同时也对程序员在使用消息队列的时候如何保证例如:生产者如何保证数据一定入队了?消费者如何保证这条消息是消费成功的? 消费消息的时候的幂等性如何保证?

下边我将对常用的两种消息队列进行着三个方面的分析:

- Rabbitmq

	1. 保证MQ本身不丢失:将RabbitMQ持久化分两步走,设置队列的时候设置为持久化,会将元数据持久化,然后发送消息的时候设置deliveryMode=2 这样就保证了数据尽可能都持久化下来
	2. 生产者一定入队:两种方式,第一种开启提供的事务,是同步阻塞的可能造成吞吐量下降.第二种开启confirm模式,异步的方式,写入成功回调成功,不成功的话回调失败,重新发送即可. 一般confirm模式和上边的持久化关联使用,只有消息在持久化到磁盘的时候才算成功
	3. 消费者不丢失: 关闭rabbitmq提供的ack机制,然后自己确认消费成功后调用Api返回消费成功(注意消费的时候幂等性)

- Kafka

	1. 保证Kafka本身不丢失

		需要设置四个参数
		
		设置该topic的replication.factor>1,保证每个partition必须至少有两个副本
		
		设置生产者ack=all:消息入队的时候当消息分布在所有的副本中才算入队成功
		
		在kafka服务端设置min.insync.replicas>1,保证每个leader至少有一个跟随者,这样当leader挂了才后继有人
		
		producer端设置retries=MAX,重试次数尽可能大,无限大,没收到ack尽可能多的重试
		
	2. 生产者消息丢失

		经过啊上边的设置 ack=all,retries=很大的数,基本不会出现生产者入不了队的情况
		
	3. 消费者没消费但是已经告诉kafka消费了

		消费者还没真正的消费的时候把offset提交了,kafka任务你消费过了,导致消费不到的情况,
		
		只要关闭自动提交offset(同样的要考虑到幂等性)
		
		比如消费了一部分消息,但是还没提交offset,kafka认为你还没消费这几条数据,下次重新运行的时候要保证
		消费的幂等性,不管消费多少次,结果都是一样的
		
- 如何保证消费的幂等性

	1. 使用MySQL主键唯一或者唯一索引约束,插入消费记录的时候会报错,那这条就不消费了
	2. 使用Redis,生产者发送每条数据的时候,生成全局唯一id,拿到的时候先去redis看这个id消费过没

	
		
		
		
		
		
		

