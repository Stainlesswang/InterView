## MCA流程改造

>mca在做什么?
>
> 1. 转码写入媒体库之后会发对应的事件到`Trigger`, v`ideo_ai`转存到`Kafka`(*目的是提供按照不同消息粒度背压能力*)
>
> 2. `video_ai`项目主要作用是在, 消费Kafka不同`topic`中的消息进行创建/唤醒 `weibo-flow`中的DAG图/节点, 每个节点由`weibo-flow`带上参数去调用相关`function`
> 
> 遇到问题: 消费速度缓慢导致数据堆积到kafka几十万数据

> 一次拉取消息500条, 如果redis中该mediaId锁未释放说明有其他消息来过,尝试忙等待5s去获取DAG图ID,这批消息消耗为`500*5/60=41 `分钟之久, 因为执行时间过长触发`session_timeout`, 造成**kafka**消息堆积
>
> 目前代码中需要改造的点
> 
> 1. 使用redis的`setnx`+过期时间三天对同一个`mediaId`的不同时间过来进行加锁, 无解锁
> 2. 目前两台队列机,单台队列机起一个线程消费并串行执行一次500条消息一系列操作
> 3. 降级操作复杂繁冗,降级一个子任务需要修改多张图



### **一. MCA锁优化(Done)**

现状: SETNX加锁, 无解锁, 超时时间为3天

同一个mediaId不同事件到来使用Redisson加锁并解锁,流程见下图[整体流程图](#anchortext)


### **二. kafka消费多线程改造(Done)**

**topic汇总:**

- `mca_wb_published`  分区: 50个
- `mca_video_dna_snapshots_hd` 分区: 50个
- `mca_ai_analysis_screenshot` 分区: 50个
- `mca_finish_upload` 分区: 50个
- `mca_audio_wav` 分区: 50个

**Consumer现状:**

以`mca_audio_wav`为例, 共两台机器, 每台机器起一个线程进行消费,一次500条串行

**改造后的消费模型:**
 
1. 一个进程对应一个consumer, 每个**consumer**拉取到的任务通过多个**Handler**也即多个线程中提高消费能力, (拒绝策略采用`callerRun`的方式,不能提交过快, kafka做背压)

<img src=http://git.intra.weibo.com/im/form/uploads/847ba8886e18121d01a05b1bd71cb541/image.png width=600 height=500 />


### **三. video-ai提供背压逻辑**

<a id="anchortext" />整体流程图:</a>
<img src=http://git.intra.weibo.com/im/form/uploads/8a7e4b04dd349208d07846870572c193/image.png width=800 height=700 />


### **四. DAG图改造,提供手动降级能力,提供单个function跳过写资源**

MCA内容理解要去做什么任务上游依赖转码输出

例如: 是否有音频? 是否产生了需要关注的截图信息? 进而去决定需要执行DAG中的哪些任务,比如有音频的转码输出则进行音频的ASR(语音转字幕识别)和ACR(音乐识别)

**目前的做法:** 转码根据木林森中配置决定需要做什么任务, 也即内容理解同样根据该配置去决定要做什么任务, 去创建各种任务组合起来的多张图


**改造: 任务全在一张图中, 可以由video_ai去判断执行哪些,跳过哪些任务**

图总共只有一个: 当音频事件到达的时候, 唤醒`audio`节点, 根据audio对应function能力去决定执行哪个跳过哪个? 

<!--<img src=http://git.intra.weibo.com/im/form/uploads/7dcfba6321dc0bbaf1aca4248b038bf3/image.png width=800 height=100 />-->

DAGOld
<img src=http://git.intra.weibo.com/im/form/uploads/a544733d888943e35c811ec4cd67360e/image.png width=800 height=400 />

DAGFunctionTodo
<img src=http://git.intra.weibo.com/im/form/uploads/78500119add23f83eda949508278aec8/image.png width=800 height=400 />

#### 新增的Todo 节点包括的能力:

- 新增的DO节点可以由入参判断是否跳过后续节点(也即控制权在video-ai处)
- function提供检查后置函数资源情况, 决定是否跳过
-  function可以根据AB策略判断是否执行后续任务

方案:新增一个fuction: **checkResourceLimit**, 做的内容是检查依赖函数是否resource limit了

提交流程:

将resource limit跳过的数据写入redis中,计算堆积大概需要多少



### **四. fucntion堆积写入MySQL**

目前停止消费的逻辑:

一个定时线程去监控function队列的等待长度,**1000停读**对应的Consumer,**800起读**

```plantuml
video_ai -> weibo_flow : submit/wakeup
weibo_flow -> weibo_function : invoke()
weibo_function -> video_ai : store(mediaId,executeId,content)
note right:resource limit
video_ai -> weibo_function : isSkip()=false
note left:save to DB
loop
weibo_function -> video_ai : batchGetTask()
video_ai -> weibo_function : (DAG executeId,content)
end
```

MySQL字段说明:

| 字段 | 类型 | 说明|
| ------ | ------ | ------ |
| id | int | 主键自增|
| media_id | bigint | 视频id|
| execute_id | varchar() | Dag图id|
| function_name | bigint | 函数名称|
| content | varchar |function执行所需json字段|
| state | int |堆积数据状态 默认0:待执行, 1:已执行 2:跳过执行|
| create_time |datetime | 创建时间|
| update_time |datetime| 更新时间|

MySQL使用情况:

日均QPS: 15
峰值QPS: 40
数据存储


docker run  -p 7979:7979 -v /data0/data1/burui_workspace/monitor/json-explorer/config.yml:/config.yml --name json_exporter  quay.io/prometheuscommunity/json-exporter --config.file=/config.yml

 
<!--<img src=http://git.intra.weibo.com/im/form/uploads/b4a9e51682b22572ec92e56b5e4e464d/image.png width=800 height=800 />-->


docker -d -p 9116:9116 --name json_exporter json_exporter




流程分布

1. 确定消息是submit还是notify
2. submit
    - 根据配置确定哪些消息不会触达 将参数set进去
    - 确定当前消息所属子任务是否需要降级? 将参数set进去
    - 执行submit
3. notify
    - 当前消息子任务是否需要降级? 将参数set进去
    - notify 
4. 灰度的时候,如何选择部分任务去执行我自己图?
    - 首先在10%的灰度上执行新的图, submit的话需要穿跳过哪些lable?
    - 其次在消息来的时候,写死

要做什么事情呢?

1. mca事件的降级 switch+lable去决定一个事件是否跳过, 这是对
3. 事件的子任务  当前消息的子任务有哪些? 这些子任务需不需要做?
跳过的逻辑为: switch+灰度比例+任务资源是否满足(这样的类型需要打日志)


data mesh

1. 媒体库



平台接入MC Mesh
https://docs.qq.com/sheet/DVkJ6UFJhZXdNR0xY




这个是接入的文档，http://git.intra.weibo.com/platform/resportal/-/issues/75